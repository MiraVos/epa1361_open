{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Sensitivity analysis\n",
    "\n",
    "This exercise uses the same predator-prey model we used for the multi-model exercise, focusing on the Python version. As with the other exercise, define a model object for the function below, with the uncertainty ranges provided:\n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging\n",
    "\n",
    "from ema_workbench import Samplers\n",
    "\n",
    "from ema_workbench.analysis import feature_scoring\n",
    "from ema_workbench.analysis.scenario_discovery_util import RuleInductionType\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem\n",
    "from SALib.analyze import sobol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pred_prey(prey_birth_rate=0.025, predation_rate=0.0015, predator_efficiency=0.002,\n",
    "             predator_loss_rate=0.06, initial_prey=50, initial_predators=20, dt=0.25,\n",
    "             final_time=365, reps=1):\n",
    "\n",
    "    #Initial values\n",
    "    predators = np.zeros((reps, int(final_time/dt)+1))\n",
    "    prey = np.zeros((reps, int(final_time/dt)+1))\n",
    "    sim_time = np.zeros((reps, int(final_time/dt)+1))\n",
    "\n",
    "    for r in range(reps):\n",
    "\n",
    "        predators[r,0] = initial_predators\n",
    "        prey[r,0] = initial_prey\n",
    "\n",
    "    #Calculate the time series\n",
    "    for t in range(0, sim_time.shape[1]-1):\n",
    "\n",
    "        dx = (prey_birth_rate*prey[r,t]) - (predation_rate*prey[r,t]*predators[r,t])\n",
    "        dy = (predator_efficiency*predators[r,t]*prey[r,t]) - (predator_loss_rate*predators[r,t])\n",
    "\n",
    "        prey[r,t+1] = max(prey[r,t] + dx*dt, 0)\n",
    "        predators[r,t+1] = max(predators[r,t] + dy*dt, 0)\n",
    "        sim_time[r,t+1] = (t+1)*dt\n",
    "\n",
    "    #Return outcomes\n",
    "    return {'TIME':sim_time,\n",
    "            'predators':predators,\n",
    "            'prey':prey}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome # Constant #TimeSeriesOutcome #IntegerParameter, BinaryParameter, CategoricalParameter\n",
    "\n",
    "model = Model('PredPrey', function=pred_prey)\n",
    "\n",
    "# Specify uncertainties, names of parameters need to match key word in the function\n",
    "model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035), #IntegerParameter, BinaryParameter, CategoricalParameter\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency',0.001, 0.004),\n",
    "                       RealParameter('predator_loss_rate',0.04, 0.08)]\n",
    "\n",
    "# Set levers, one for each time step\n",
    "#model.levers = [RealParameter('l'+str(i), 0, 0.1) for i in range(100)]\n",
    "\n",
    "# Specify outcomes\n",
    "model.outcomes = [TimeSeriesOutcome('TIME'), #time\n",
    "                  TimeSeriesOutcome('predators'), #predator\n",
    "                  TimeSeriesOutcome('prey')] #prey\n",
    "\n",
    "#model.constants = [Constant('final_time', 365), \n",
    "#                    Constant('dt', 0.25)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 1. Sensitivity analysis\n",
    "Sensitivity analysis often focuses on the final values of an outcome at the end of the simulation. However, we can also look at metrics that give us additional information about the behavior of the model over time. Using [the statsmodel library](https://www.statsmodels.org/stable/index.html) and an appropriate sampling design, fit a linear regression model for each of the following indicators. What can we conclude about the behavior of the model, and about the importance of the different inputs?\n",
    "\n",
    "  * The final values of the _prey_ outcome\n",
    "  * The mean values of the _prey_ outcome over time, within each experiment\n",
    "  * The standard deviations of the _prey_ outcome over time, within each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 50/50 [00:00<00:00, 129.90it/s]\n"
     ]
    }
   ],
   "source": [
    "#Sampling design\n",
    "from ema_workbench import SequentialEvaluator\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=50) #default sampling method uniform distribution with Latin-Hypercube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>predation_rate</th>\n      <th>predator_efficiency</th>\n      <th>predator_loss_rate</th>\n      <th>prey_birth_rate</th>\n      <th>scenario</th>\n      <th>policy</th>\n      <th>model</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.001200</td>\n      <td>0.002085</td>\n      <td>0.070508</td>\n      <td>0.018696</td>\n      <td>0</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.002262</td>\n      <td>0.003287</td>\n      <td>0.052081</td>\n      <td>0.021858</td>\n      <td>1</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.002465</td>\n      <td>0.002920</td>\n      <td>0.046979</td>\n      <td>0.016605</td>\n      <td>2</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.001650</td>\n      <td>0.002265</td>\n      <td>0.041849</td>\n      <td>0.028855</td>\n      <td>3</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.002659</td>\n      <td>0.002538</td>\n      <td>0.075270</td>\n      <td>0.023005</td>\n      <td>4</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.001823</td>\n      <td>0.001741</td>\n      <td>0.057729</td>\n      <td>0.019374</td>\n      <td>5</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.000788</td>\n      <td>0.003523</td>\n      <td>0.073030</td>\n      <td>0.016537</td>\n      <td>6</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.002158</td>\n      <td>0.001405</td>\n      <td>0.078857</td>\n      <td>0.023816</td>\n      <td>7</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.002708</td>\n      <td>0.001991</td>\n      <td>0.060624</td>\n      <td>0.017331</td>\n      <td>8</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.001558</td>\n      <td>0.001070</td>\n      <td>0.066570</td>\n      <td>0.027557</td>\n      <td>9</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.001352</td>\n      <td>0.003363</td>\n      <td>0.056981</td>\n      <td>0.029761</td>\n      <td>10</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.001762</td>\n      <td>0.003065</td>\n      <td>0.065616</td>\n      <td>0.017617</td>\n      <td>11</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.001977</td>\n      <td>0.002643</td>\n      <td>0.069751</td>\n      <td>0.024440</td>\n      <td>12</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.001337</td>\n      <td>0.001702</td>\n      <td>0.049779</td>\n      <td>0.026133</td>\n      <td>13</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.001623</td>\n      <td>0.003197</td>\n      <td>0.055500</td>\n      <td>0.029999</td>\n      <td>14</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.001530</td>\n      <td>0.003426</td>\n      <td>0.061480</td>\n      <td>0.021452</td>\n      <td>15</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0.001107</td>\n      <td>0.003957</td>\n      <td>0.071726</td>\n      <td>0.033039</td>\n      <td>16</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.002036</td>\n      <td>0.002738</td>\n      <td>0.054786</td>\n      <td>0.027017</td>\n      <td>17</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.002366</td>\n      <td>0.003250</td>\n      <td>0.048107</td>\n      <td>0.030884</td>\n      <td>18</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.000584</td>\n      <td>0.002817</td>\n      <td>0.049174</td>\n      <td>0.034921</td>\n      <td>19</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>0.000532</td>\n      <td>0.001659</td>\n      <td>0.078335</td>\n      <td>0.026844</td>\n      <td>20</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.000828</td>\n      <td>0.001431</td>\n      <td>0.045059</td>\n      <td>0.025357</td>\n      <td>21</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.002859</td>\n      <td>0.003734</td>\n      <td>0.065109</td>\n      <td>0.031619</td>\n      <td>22</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.001249</td>\n      <td>0.003490</td>\n      <td>0.050422</td>\n      <td>0.022620</td>\n      <td>23</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.002083</td>\n      <td>0.001255</td>\n      <td>0.045919</td>\n      <td>0.024708</td>\n      <td>24</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.002613</td>\n      <td>0.003839</td>\n      <td>0.040637</td>\n      <td>0.031018</td>\n      <td>25</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.002242</td>\n      <td>0.003024</td>\n      <td>0.044598</td>\n      <td>0.015258</td>\n      <td>26</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.001460</td>\n      <td>0.001122</td>\n      <td>0.051421</td>\n      <td>0.019698</td>\n      <td>27</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.000966</td>\n      <td>0.002175</td>\n      <td>0.054100</td>\n      <td>0.018322</td>\n      <td>28</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>0.002569</td>\n      <td>0.003900</td>\n      <td>0.058774</td>\n      <td>0.033889</td>\n      <td>29</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>0.001885</td>\n      <td>0.002790</td>\n      <td>0.052864</td>\n      <td>0.031872</td>\n      <td>30</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>0.000694</td>\n      <td>0.003611</td>\n      <td>0.069007</td>\n      <td>0.034329</td>\n      <td>31</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>0.002533</td>\n      <td>0.002911</td>\n      <td>0.068696</td>\n      <td>0.028055</td>\n      <td>32</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>0.001711</td>\n      <td>0.001551</td>\n      <td>0.056197</td>\n      <td>0.029140</td>\n      <td>33</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>0.002310</td>\n      <td>0.002056</td>\n      <td>0.043876</td>\n      <td>0.020339</td>\n      <td>34</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0.002996</td>\n      <td>0.001347</td>\n      <td>0.076198</td>\n      <td>0.026382</td>\n      <td>35</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0.000929</td>\n      <td>0.002588</td>\n      <td>0.079712</td>\n      <td>0.020966</td>\n      <td>36</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0.001908</td>\n      <td>0.001902</td>\n      <td>0.059755</td>\n      <td>0.019846</td>\n      <td>37</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0.002407</td>\n      <td>0.001849</td>\n      <td>0.072683</td>\n      <td>0.015458</td>\n      <td>38</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>0.001419</td>\n      <td>0.001041</td>\n      <td>0.074873</td>\n      <td>0.021078</td>\n      <td>39</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>0.002123</td>\n      <td>0.003153</td>\n      <td>0.077545</td>\n      <td>0.025562</td>\n      <td>40</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>0.000731</td>\n      <td>0.001797</td>\n      <td>0.042973</td>\n      <td>0.015839</td>\n      <td>41</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>0.002937</td>\n      <td>0.001486</td>\n      <td>0.047461</td>\n      <td>0.033795</td>\n      <td>42</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>0.001006</td>\n      <td>0.002477</td>\n      <td>0.064180</td>\n      <td>0.032267</td>\n      <td>43</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>0.000636</td>\n      <td>0.003776</td>\n      <td>0.067383</td>\n      <td>0.032811</td>\n      <td>44</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>0.002849</td>\n      <td>0.003681</td>\n      <td>0.041018</td>\n      <td>0.023788</td>\n      <td>45</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>0.000885</td>\n      <td>0.002378</td>\n      <td>0.062493</td>\n      <td>0.022552</td>\n      <td>46</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>0.002769</td>\n      <td>0.002397</td>\n      <td>0.061734</td>\n      <td>0.030314</td>\n      <td>47</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>0.001295</td>\n      <td>0.001236</td>\n      <td>0.074185</td>\n      <td>0.028247</td>\n      <td>48</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>0.001100</td>\n      <td>0.002234</td>\n      <td>0.063503</td>\n      <td>0.017925</td>\n      <td>49</td>\n      <td>None</td>\n      <td>PredPrey</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    predation_rate  predator_efficiency  predator_loss_rate  prey_birth_rate   \n0         0.001200             0.002085            0.070508         0.018696  \\\n1         0.002262             0.003287            0.052081         0.021858   \n2         0.002465             0.002920            0.046979         0.016605   \n3         0.001650             0.002265            0.041849         0.028855   \n4         0.002659             0.002538            0.075270         0.023005   \n5         0.001823             0.001741            0.057729         0.019374   \n6         0.000788             0.003523            0.073030         0.016537   \n7         0.002158             0.001405            0.078857         0.023816   \n8         0.002708             0.001991            0.060624         0.017331   \n9         0.001558             0.001070            0.066570         0.027557   \n10        0.001352             0.003363            0.056981         0.029761   \n11        0.001762             0.003065            0.065616         0.017617   \n12        0.001977             0.002643            0.069751         0.024440   \n13        0.001337             0.001702            0.049779         0.026133   \n14        0.001623             0.003197            0.055500         0.029999   \n15        0.001530             0.003426            0.061480         0.021452   \n16        0.001107             0.003957            0.071726         0.033039   \n17        0.002036             0.002738            0.054786         0.027017   \n18        0.002366             0.003250            0.048107         0.030884   \n19        0.000584             0.002817            0.049174         0.034921   \n20        0.000532             0.001659            0.078335         0.026844   \n21        0.000828             0.001431            0.045059         0.025357   \n22        0.002859             0.003734            0.065109         0.031619   \n23        0.001249             0.003490            0.050422         0.022620   \n24        0.002083             0.001255            0.045919         0.024708   \n25        0.002613             0.003839            0.040637         0.031018   \n26        0.002242             0.003024            0.044598         0.015258   \n27        0.001460             0.001122            0.051421         0.019698   \n28        0.000966             0.002175            0.054100         0.018322   \n29        0.002569             0.003900            0.058774         0.033889   \n30        0.001885             0.002790            0.052864         0.031872   \n31        0.000694             0.003611            0.069007         0.034329   \n32        0.002533             0.002911            0.068696         0.028055   \n33        0.001711             0.001551            0.056197         0.029140   \n34        0.002310             0.002056            0.043876         0.020339   \n35        0.002996             0.001347            0.076198         0.026382   \n36        0.000929             0.002588            0.079712         0.020966   \n37        0.001908             0.001902            0.059755         0.019846   \n38        0.002407             0.001849            0.072683         0.015458   \n39        0.001419             0.001041            0.074873         0.021078   \n40        0.002123             0.003153            0.077545         0.025562   \n41        0.000731             0.001797            0.042973         0.015839   \n42        0.002937             0.001486            0.047461         0.033795   \n43        0.001006             0.002477            0.064180         0.032267   \n44        0.000636             0.003776            0.067383         0.032811   \n45        0.002849             0.003681            0.041018         0.023788   \n46        0.000885             0.002378            0.062493         0.022552   \n47        0.002769             0.002397            0.061734         0.030314   \n48        0.001295             0.001236            0.074185         0.028247   \n49        0.001100             0.002234            0.063503         0.017925   \n\n   scenario policy     model  \n0         0   None  PredPrey  \n1         1   None  PredPrey  \n2         2   None  PredPrey  \n3         3   None  PredPrey  \n4         4   None  PredPrey  \n5         5   None  PredPrey  \n6         6   None  PredPrey  \n7         7   None  PredPrey  \n8         8   None  PredPrey  \n9         9   None  PredPrey  \n10       10   None  PredPrey  \n11       11   None  PredPrey  \n12       12   None  PredPrey  \n13       13   None  PredPrey  \n14       14   None  PredPrey  \n15       15   None  PredPrey  \n16       16   None  PredPrey  \n17       17   None  PredPrey  \n18       18   None  PredPrey  \n19       19   None  PredPrey  \n20       20   None  PredPrey  \n21       21   None  PredPrey  \n22       22   None  PredPrey  \n23       23   None  PredPrey  \n24       24   None  PredPrey  \n25       25   None  PredPrey  \n26       26   None  PredPrey  \n27       27   None  PredPrey  \n28       28   None  PredPrey  \n29       29   None  PredPrey  \n30       30   None  PredPrey  \n31       31   None  PredPrey  \n32       32   None  PredPrey  \n33       33   None  PredPrey  \n34       34   None  PredPrey  \n35       35   None  PredPrey  \n36       36   None  PredPrey  \n37       37   None  PredPrey  \n38       38   None  PredPrey  \n39       39   None  PredPrey  \n40       40   None  PredPrey  \n41       41   None  PredPrey  \n42       42   None  PredPrey  \n43       43   None  PredPrey  \n44       44   None  PredPrey  \n45       45   None  PredPrey  \n46       46   None  PredPrey  \n47       47   None  PredPrey  \n48       48   None  PredPrey  \n49       49   None  PredPrey  "
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[49.49308686574551,\n 3.5913245254361414,\n 2.7957825671489496,\n 17.909758539276293,\n 14.909126231812124,\n 52.565616195489284,\n 13.320945054467883,\n 50.22135675048127,\n 26.38998896835544,\n 72.89789818616244,\n 42.24085469456313,\n 14.276836880358038,\n 16.054901534951448,\n 51.45345530455229,\n 46.37370967149409,\n 12.88159626267565,\n 3.1619651061490184,\n 45.09686113875378,\n 13.647185621654785,\n 32.19867090306169,\n 29.090882817439695,\n 38.20211829948692,\n 17.308833900991697,\n 2.6480962997861153,\n 61.085080433071624,\n 0.4844463954589471,\n 53.08991388541312,\n 60.31376179519413,\n 18.939762988460505,\n 55.23269396630813,\n 45.91685595896273,\n 3.5360653926582684,\n 7.576779032614557,\n 25.317902239584765,\n 6.985581495791229,\n 45.53363388867848,\n 23.76783959610862,\n 54.1119696055869,\n 56.58207529838989,\n 54.60217448729153,\n 8.177538454046433,\n 8.64202878052567,\n 16.056823117500127,\n 9.207780667023128,\n 21.011469100400785,\n 0.5079291163959797,\n 51.426883724908734,\n 8.490300023501671,\n 65.35824079207359,\n 38.1166826913457]"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lastout = []\n",
    "for i in range(0,50,1):\n",
    "    lastout.append(outcomes['prey'][i][0][1460]) #a time series of possible outcomes at \n",
    "lastout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.535\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.526\n",
      "Method:                 Least Squares   F-statistic:                              56.39\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    1.08e-09\n",
      "Time:                        17:04:48   Log-Likelihood:                          261.73\n",
      "No. Observations:                  50   AIC:                                     -521.5\n",
      "Df Residuals:                      49   BIC:                                     -519.5\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          3.832e-05    5.1e-06      7.509      0.000    2.81e-05    4.86e-05\n",
      "==============================================================================\n",
      "Omnibus:                        7.899   Durbin-Watson:                   1.791\n",
      "Prob(Omnibus):                  0.019   Jarque-Bera (JB):                3.032\n",
      "Skew:                           0.275   Prob(JB):                        0.220\n",
      "Kurtosis:                       1.927   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.434\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.422\n",
      "Method:                 Least Squares   F-statistic:                              37.53\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    1.49e-07\n",
      "Time:                        17:04:48   Log-Likelihood:                          240.06\n",
      "No. Observations:                  50   AIC:                                     -478.1\n",
      "Df Residuals:                      49   BIC:                                     -476.2\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          4.823e-05   7.87e-06      6.126      0.000    3.24e-05     6.4e-05\n",
      "==============================================================================\n",
      "Omnibus:                        4.382   Durbin-Watson:                   1.514\n",
      "Prob(Omnibus):                  0.112   Jarque-Bera (JB):                2.205\n",
      "Skew:                          -0.226   Prob(JB):                        0.332\n",
      "Kurtosis:                       2.076   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.664\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.657\n",
      "Method:                 Least Squares   F-statistic:                              96.75\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    3.47e-13\n",
      "Time:                        17:04:48   Log-Likelihood:                          96.110\n",
      "No. Observations:                  50   AIC:                                     -190.2\n",
      "Df Residuals:                      49   BIC:                                     -188.3\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0014      0.000      9.836      0.000       0.001       0.002\n",
      "==============================================================================\n",
      "Omnibus:                       11.021   Durbin-Watson:                   1.560\n",
      "Prob(Omnibus):                  0.004   Jarque-Bera (JB):                3.284\n",
      "Skew:                          -0.226   Prob(JB):                        0.194\n",
      "Kurtosis:                       1.829   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.605\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.597\n",
      "Method:                 Least Squares   F-statistic:                              75.17\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    1.84e-11\n",
      "Time:                        17:04:48   Log-Likelihood:                          135.49\n",
      "No. Observations:                  50   AIC:                                     -269.0\n",
      "Df Residuals:                      49   BIC:                                     -267.1\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0006   6.37e-05      8.670      0.000       0.000       0.001\n",
      "==============================================================================\n",
      "Omnibus:                        8.083   Durbin-Watson:                   1.228\n",
      "Prob(Omnibus):                  0.018   Jarque-Bera (JB):                2.689\n",
      "Skew:                          -0.146   Prob(JB):                        0.261\n",
      "Kurtosis:                       1.902   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.650\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.643\n",
      "Method:                 Least Squares   F-statistic:                              90.88\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    9.60e-13\n",
      "Time:                        17:04:48   Log-Likelihood:                          268.81\n",
      "No. Observations:                  50   AIC:                                     -535.6\n",
      "Df Residuals:                      49   BIC:                                     -533.7\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          5.016e-05   5.26e-06      9.533      0.000    3.96e-05    6.07e-05\n",
      "==============================================================================\n",
      "Omnibus:                        1.377   Durbin-Watson:                   1.995\n",
      "Prob(Omnibus):                  0.502   Jarque-Bera (JB):                1.382\n",
      "Skew:                          -0.355   Prob(JB):                        0.501\n",
      "Kurtosis:                       2.600   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.864\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.862\n",
      "Method:                 Least Squares   F-statistic:                              312.6\n",
      "Date:                Thu, 11 May 2023   Prob (F-statistic):                    6.59e-23\n",
      "Time:                        17:04:49   Log-Likelihood:                          292.55\n",
      "No. Observations:                  50   AIC:                                     -583.1\n",
      "Df Residuals:                      49   BIC:                                     -581.2\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             0.0001   6.58e-06     17.680      0.000       0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                        4.227   Durbin-Watson:                   2.310\n",
      "Prob(Omnibus):                  0.121   Jarque-Bera (JB):                3.886\n",
      "Skew:                          -0.613   Prob(JB):                        0.143\n",
      "Kurtosis:                       2.400   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#Linear regression for prey outcome\n",
    "model = sm.OLS(experiments['predation_rate'].values, np.array(lastout))\n",
    "results1 = model.fit()\n",
    "print(results.summary())\n",
    "\n",
    "model = sm.OLS(experiments['predator_efficiency'].values, np.array(lastout))\n",
    "results2 = model.fit()\n",
    "print(results2.summary())\n",
    "\n",
    "model = sm.OLS(experiments['predator_loss_rate'].values, np.array(lastout))\n",
    "results3 = model.fit()\n",
    "print(results3.summary())\n",
    "\n",
    "model = sm.OLS(experiments['prey_birth_rate'].values, np.array(lastout))\n",
    "results4 = model.fit()\n",
    "print(results4.summary())\n",
    "\n",
    "#Linear regression for mean prey outcome over time \n",
    "lastoutm = []\n",
    "for i in range(0,50,1):\n",
    "    lastoutm.append(outcomes['prey'][i][0].mean()) #a time series of possible outcomes at \n",
    "lastoutm\n",
    "\n",
    "model = sm.OLS(experiments['predation_rate'].values, np.array(lastoutm))\n",
    "results5 = model.fit()\n",
    "print(results5.summary())\n",
    "\n",
    "#Linear regression for sdv prey outcome over time\n",
    "lastouts = []\n",
    "for i in range(0,50,1):\n",
    "    lastouts.append(outcomes['prey'][i][0].std()) #a time series of possible outcomes at \n",
    "lastouts\n",
    "\n",
    "model = sm.OLS(experiments['predation_rate'].values, np.array(lastouts))\n",
    "results6 = model.fit()\n",
    "print(results6.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 2. SOBOL\n",
    "Use the Sobol sampling functionality included in the Workbench to perform experiments with a sample size of N=50, then analyze the results with SALib for the same three indicators. This requires specifying the keyword argument `'uncertainty_sampling'` of perform_experiments. Note that when using Sobol sampling, the meaning of the keyword argument `scenarios` changes a bit. In order to properly estimate Sobol scores as well as interaction effects, you require N * (2D+2) scenarios, where D is the number of uncertain parameters, and N is the value for scenarios passed to `perform_experiments`. Repeat the analysis for larger sample sizes, with N=250 and N=1000. How can we interpret the first-order and total indices? Are these sample sizes sufficient for a stable estimation of the indices? You'll need to use the [get_SALib_problem](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/em_framework/salib_samplers.html) function to convert your Workbench experiments to a problem definition that you can pass to the SALib analysis function.\n",
    "\n",
    "*hint*: sobol is a deterministic sequence of quasi random numbers. Thus, you can run with N=1000 and simply use slicing to get the results for N=50 and N=250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### 3. Extra trees\n",
    "Use the [Extra-Trees analysis](https://emaworkbench.readthedocs.io/en/latest/ema_documentation/analysis/feature_scoring.html) included in the Workbench to approximate the Sobol total indices, with a suitable sampling design. As a starting point, use an ensemble of 100 trees and a max_features parameter of 0.6, and set the analysis to regression mode. Are the estimated importances stable relative to the sample size and the analysis parameters? How do the results compare to the Sobol indices? For more details on this analysis see [Jaxa-Rozen & Kwakkel (2018)](https://www.sciencedirect.com/science/article/pii/S1364815217311581)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}