{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EPA1361 - Model-Based Decision Making\n",
    "\n",
    "## Multi-model analysis\n",
    "\n",
    "This exercise uses a simple version of the [Lotka-Volterra predator-prey equations](https://en.wikipedia.org/wiki/Lotka%E2%80%93Volterra_equations) to show how the EMA Workbench can be used for a\n",
    "multi-model analysis, in addition to typical parametric/structural uncertainties. This will let you test the connectors provided in the Workbench for Excel, NetLogo, and Vensim / PySD; we'll also use the models for the sensitivity analysis exercise in week 3.\n",
    "\n",
    "**Assignment**\n",
    "Using the three model files provided and the Python function below, define model objects for each implementation (Excel, NetLogo, Vensim/PySD, and Python), and test them using a single ensemble. Use 50 experiments sampled from the parameters below (so that each experiment will be executed for the 4 models, for a total of 200), and retrieve outputs for the _TIME_, _predators_, and _prey_ variables.\n",
    "   * Excel and Vensim are only supported on Windows\n",
    "   * Vensim requires the DSS version of Vensim\n",
    "   * Netlogo supoprt depends on [jpype](http://jpype.readthedocs.io/en/latest/install.html) and [pynetlogo](https://pynetlogo.readthedocs.io/en/latest/). Also, if you don't have NetLogo installed, please get [NetLogo 6.3.0](https://ccl.northwestern.edu/netlogo/download.shtml)\n",
    "   * for pysd, see [its documentation](http://pysd.readthedocs.io/en/master/installation.html)\n",
    "   * If possible try to work with all model versions, but even 2 or 3 (pure python and something else should be sufficient).\n",
    "\n",
    "\n",
    "|Parameter\t|Range or value\t        |\n",
    "|-----------|--------------:|\n",
    "|prey_birth_rate    \t|0.015 – 0.035\t|\n",
    "|predation_rate|0.0005 – 0.003 \t|\n",
    "|predator_efficiency     \t|0.001 – 0.004\t    |\n",
    "|predator_loss_rate\t    |0.04 – 0.08\t    |\n",
    "|Final time\t    |365\t    |\n",
    "|dt\t    |0.25\t    |\n",
    "\n",
    "* Note that your EMA Workbench installation includes [example scripts](https://github.com/quaquel/EMAworkbench/tree/master/ema_workbench/examples) for the different connectors. The different model objects follow a similar syntax but will need to be slightly adjusted depending on the software (e.g. to specify the NetLogo run length or the sheet name in Excel).\n",
    "  * This [tutorial](https://emaworkbench.readthedocs.io/en/latest/basic_tutorial.html) also shows a simple model in Python, Vensim and Excel connected to the workbench.\n",
    "\n",
    "* These model objects can be used with a replication functionality (for instance to test the effect of stochastic uncertainty in a NetLogo model), which repeats a given experiment over multiple replications. You can use a single replication in this exercise as the models are not stochastic. By default, each outcome array will then have a shape of (# experiments, # replications, # time steps). Try adapting the outcome arrays so that they can be used with the _lines_ plotting function of the Workbench, and plot the results grouped by model.\n",
    "\n",
    "* To check the graphical results, find the maximum absolute error of the time series you obtained for the _prey_ variable in the Excel, NetLogo, and Vensim/PySD models, relative to the Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.448651Z",
     "start_time": "2023-04-07T13:56:49.471035Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mira/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/analysis/prim.py:30: ImportWarning: altair based interactive inspection not available\n",
      "  warnings.warn((\"altair based interactive \" \"inspection not available\"), ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "# Some imports you may need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ema_workbench import (Model, RealParameter, TimeSeriesOutcome, perform_experiments, ema_logging)\n",
    "\n",
    "from ema_workbench.connectors.netlogo import NetLogoModel\n",
    "from ema_workbench.connectors.excel import ExcelModel\n",
    "from ema_workbench.connectors.pysd_connector import PysdModel\n",
    "\n",
    "from ema_workbench.em_framework.samplers import LHSSampler\n",
    "from ema_workbench.em_framework.salib_samplers import MorrisSampler, SobolSampler\n",
    "\n",
    "from ema_workbench.analysis.plotting import lines, Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.450975Z",
     "start_time": "2023-04-07T13:56:51.445849Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the Python function\n",
    "from model.pred_prey import PredPrey\n",
    "\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome, Constant #TimeSeriesOutcome #IntegerParameter, BinaryParameter, CategoricalParameter\n",
    "\n",
    "model = Model('PreyPy', function=PredPrey)\n",
    "\n",
    "# Specify uncertainties, names of parameters need to match key word in the function\n",
    "model.uncertainties = [RealParameter('prey_birth_rate', 0.015, 0.035), #IntegerParameter, BinaryParameter, CategoricalParameter\n",
    "                       RealParameter('predation_rate', 0.0005, 0.003),\n",
    "                       RealParameter('predator_efficiency',0.001, 0.004),\n",
    "                       RealParameter('predator_loss_rate',0.04, 0.08)]\n",
    "\n",
    "# Set levers, one for each time step\n",
    "#model.levers = [RealParameter('l'+str(i), 0, 0.1) for i in range(100)]\n",
    "\n",
    "# Specify outcomes\n",
    "model.outcomes = [TimeSeriesOutcome('TIME'), #time\n",
    "                  TimeSeriesOutcome('predator'), #predator\n",
    "                  TimeSeriesOutcome('prey')] #prey\n",
    "\n",
    "model.constants = [Constant('final_time', 365), \n",
    "                    Constant('dt', 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-07T13:56:51.453653Z",
     "start_time": "2023-04-07T13:56:51.450975Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Define uncertainties and outcomes\n",
    "\n",
    "\n",
    "# Define model objects for the different implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/50 [00:00<?, ?it/s]predator not found in model output\n"
     ]
    },
    {
     "ename": "EMAError",
     "evalue": "outcome predator should be a collection",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEMAError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mema_workbench\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SequentialEvaluator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SequentialEvaluator(model) \u001b[38;5;28;01mas\u001b[39;00m evaluator:\n\u001b[0;32m----> 4\u001b[0m     experiments, outcomes \u001b[38;5;241m=\u001b[39m evaluator\u001b[38;5;241m.\u001b[39mperform_experiments(scenarios\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:214\u001b[0m, in \u001b[0;36mBaseEvaluator.perform_experiments\u001b[0;34m(self, scenarios, policies, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, combine)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperform_experiments\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     scenarios\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m     combine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfactorial\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m ):\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;124;03m\"\"\"convenience method for performing experiments.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m    is forwarded to :func:perform_experiments, with evaluator and\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;124;03m    models arguments added in.\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \n\u001b[1;32m    213\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m perform_experiments(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_msis,\n\u001b[1;32m    216\u001b[0m         scenarios\u001b[38;5;241m=\u001b[39mscenarios,\n\u001b[1;32m    217\u001b[0m         policies\u001b[38;5;241m=\u001b[39mpolicies,\n\u001b[1;32m    218\u001b[0m         evaluator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    219\u001b[0m         reporting_interval\u001b[38;5;241m=\u001b[39mreporting_interval,\n\u001b[1;32m    220\u001b[0m         reporting_frequency\u001b[38;5;241m=\u001b[39mreporting_frequency,\n\u001b[1;32m    221\u001b[0m         uncertainty_union\u001b[38;5;241m=\u001b[39muncertainty_union,\n\u001b[1;32m    222\u001b[0m         lever_union\u001b[38;5;241m=\u001b[39mlever_union,\n\u001b[1;32m    223\u001b[0m         outcome_union\u001b[38;5;241m=\u001b[39moutcome_union,\n\u001b[1;32m    224\u001b[0m         uncertainty_sampling\u001b[38;5;241m=\u001b[39muncertainty_sampling,\n\u001b[1;32m    225\u001b[0m         lever_sampling\u001b[38;5;241m=\u001b[39mlever_sampling,\n\u001b[1;32m    226\u001b[0m         callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    227\u001b[0m         combine\u001b[38;5;241m=\u001b[39mcombine,\n\u001b[1;32m    228\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:568\u001b[0m, in \u001b[0;36mperform_experiments\u001b[0;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, return_callback, combine, log_progress)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evaluator:\n\u001b[1;32m    566\u001b[0m     evaluator \u001b[38;5;241m=\u001b[39m SequentialEvaluator(models)\n\u001b[0;32m--> 568\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mevaluate_experiments(scenarios, policies, callback, combine\u001b[38;5;241m=\u001b[39mcombine)\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callback\u001b[38;5;241m.\u001b[39mi \u001b[38;5;241m!=\u001b[39m nr_of_exp:\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EMAError(\n\u001b[1;32m    572\u001b[0m         (\n\u001b[1;32m    573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msome fatal error has occurred while \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(nr_of_exp, callback\u001b[38;5;241m.\u001b[39mi)\n\u001b[1;32m    577\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/evaluators.py:311\u001b[0m, in \u001b[0;36mSequentialEvaluator.evaluate_experiments\u001b[0;34m(self, scenarios, policies, callback, combine)\u001b[0m\n\u001b[1;32m    308\u001b[0m runner \u001b[38;5;241m=\u001b[39m ExperimentRunner(models)\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m experiment \u001b[38;5;129;01min\u001b[39;00m ex_gen:\n\u001b[0;32m--> 311\u001b[0m     outcomes \u001b[38;5;241m=\u001b[39m runner\u001b[38;5;241m.\u001b[39mrun_experiment(experiment)\n\u001b[1;32m    312\u001b[0m     callback(experiment, outcomes)\n\u001b[1;32m    313\u001b[0m runner\u001b[38;5;241m.\u001b[39mcleanup()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/util/ema_logging.py:152\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# hack, because log is applied to methods, we can get\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# object instance as first arguments in args\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/experiment_runner.py:91\u001b[0m, in \u001b[0;36mExperimentRunner.run_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m     84\u001b[0m _logger\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_message\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     86\u001b[0m         scenario_id\u001b[38;5;241m=\u001b[39mscenario_id, policy_name\u001b[38;5;241m=\u001b[39mpolicy_name, model_name\u001b[38;5;241m=\u001b[39mmodel_name\n\u001b[1;32m     87\u001b[0m     )\n\u001b[1;32m     88\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     model\u001b[38;5;241m.\u001b[39mrun_model(scenario, policy)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CaseError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     93\u001b[0m     _logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/util/ema_logging.py:152\u001b[0m, in \u001b[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;66;03m# hack, because log is applied to methods, we can get\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;66;03m# object instance as first arguments in args\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompleted calling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/model.py:341\u001b[0m, in \u001b[0;36mSingleReplication.run_model\u001b[0;34m(self, scenario, policy)\u001b[0m\n\u001b[1;32m    337\u001b[0m experiment \u001b[38;5;241m=\u001b[39m ExperimentReplication(scenario, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, constants)\n\u001b[1;32m    339\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_experiment(experiment)\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes_output \u001b[38;5;241m=\u001b[39m outputs\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstraints_output \u001b[38;5;241m=\u001b[39m (experiment, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes_output)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/model.py:68\u001b[0m, in \u001b[0;36mAbstractModel.outcomes_output\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m outcome \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes:\n\u001b[1;32m     67\u001b[0m     data \u001b[38;5;241m=\u001b[39m [outputs[var] \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m outcome\u001b[38;5;241m.\u001b[39mvariable_name]\n\u001b[0;32m---> 68\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outcomes_output[outcome\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m outcome\u001b[38;5;241m.\u001b[39mprocess(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ema_workbench/em_framework/outcomes.py:423\u001b[0m, in \u001b[0;36mArrayOutcome.process\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m    421\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mprocess(values)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[0;32m--> 423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m EMAError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutcome \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a collection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[0;31mEMAError\u001b[0m: outcome predator should be a collection"
     ]
    }
   ],
   "source": [
    "from ema_workbench import SequentialEvaluator\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}